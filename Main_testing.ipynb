{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n%pip install finvizfinance\\n%pip install pandas\\n%pip install transformers\\n%pip install yfinance\\n%pip install goose3\\n%pip install requests\\n%pip install ipywidgets\\n\\n%pip install torch\\n%pip install tensorflow\\n%pip install nltk\\nimport nltk\\nnltk.download('punkt')\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install dependencies (uncomment the following lines by removing ''' if you haven't installed the dependencies yet)\n",
    "'''\n",
    "%pip install finvizfinance\n",
    "%pip install pandas\n",
    "%pip install transformers\n",
    "%pip install yfinance\n",
    "%pip install goose3\n",
    "%pip install requests\n",
    "%pip install ipywidgets\n",
    "\n",
    "%pip install torch\n",
    "%pip install tensorflow\n",
    "%pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from finvizfinance.screener.overview import Overview # type: ignore\n",
    "from finvizfinance.quote import finvizfinance        # type: ignore\n",
    "from IPython.display import display                  # type: ignore\n",
    "\n",
    "import pandas as pd                 # type: ignore\n",
    "from transformers import pipeline   # type: ignore\n",
    "import yfinance as yf               # type: ignore\n",
    "from goose3 import Goose            # type: ignore\n",
    "from requests import get            # type: ignore\n",
    "\n",
    "from nltk.tokenize import sent_tokenize # type: ignore\n",
    "from transformers import AutoTokenizer  # type: ignore\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Other general settings\n",
    "pd.set_option('display.max_colwidth', None) # Display full text in pandas dataframe / no line wrapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nFILTERS_DICT = {'Debt/Equity':'Under 1',                 # Positive Operating Margin\\n                'PEG':'Low (<1)',                        # Debt-to-Equity ratio under 1\\n                'Operating Margin':'Positive (>0%)',     # Low P/B (under 1)\\n                'P/B':'Low (<1)',                        # Low P/E ratio (under 15)\\n                'P/E':'Low (<15)',                       # Low PEG ratio (under 1)\\n                'InsiderTransactions':'Positive (>0%)<'} # Positive Insider Transactions\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create filters dictionary, i.e filter the stocks based on the following criteria:\n",
    "FILTERS_DICT = {\n",
    "    'Performance': 'Today +10%',     # Day increase 10%\n",
    "    'Relative Volume': 'Over 5',       # High Relative Volume\n",
    "    'Price': 'Under $20',              # Price under 20 USD\n",
    "    'Float': 'Under 10M'               # Float under 10 million\n",
    "}\n",
    "\n",
    "# Alternative filtering to consider:\n",
    "'''\n",
    "FILTERS_DICT = {'Debt/Equity':'Under 1',                 # Positive Operating Margin\n",
    "                'PEG':'Low (<1)',                        # Debt-to-Equity ratio under 1\n",
    "                'Operating Margin':'Positive (>0%)',     # Low P/B (under 1)\n",
    "                'P/B':'Low (<1)',                        # Low P/E ratio (under 15)\n",
    "                'P/E':'Low (<15)',                       # Low PEG ratio (under 1)\n",
    "                'InsiderTransactions':'Positive (>0%)<'} # Positive Insider Transactions\n",
    "'''\n",
    "\n",
    "\n",
    "# The filters and general manual link for the finvizfinance library: https://finvizfinance.readthedocs.io/_/downloads/en/latest/pdf/ \n",
    "# Possible filters can be found by running the following code:\n",
    "\n",
    "#from finvizfinance.screener.overview import Overview # type: ignore\n",
    "#foverview = Overview()    # Create Overview object\n",
    "#foverview.get_filters()   # Get list of all possible filters\n",
    "\n",
    "# And after to see the possible options for a filter, run the following code:\n",
    "#foverview.get_filter_options('Relative Volume') # Get list of all possible options for a filter, example on 'Relative Volume'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] loading page [##############################] 1/1 \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Company</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Country</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>P/E</th>\n",
       "      <th>Price</th>\n",
       "      <th>Change</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTCK</td>\n",
       "      <td>Davis Commodities Ltd.</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>Farm Products</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>33320000.0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>3356710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MULN</td>\n",
       "      <td>Mullen Automotive Inc</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>Auto Manufacturers</td>\n",
       "      <td>USA</td>\n",
       "      <td>46110000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.04</td>\n",
       "      <td>0.2265</td>\n",
       "      <td>18384953.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OXBR</td>\n",
       "      <td>Oxbridge Re Holdings Ltd</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Insurance - Reinsurance</td>\n",
       "      <td>Cayman Islands</td>\n",
       "      <td>9920000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.2992</td>\n",
       "      <td>224130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REBN</td>\n",
       "      <td>Reborn Coffee Inc</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>USA</td>\n",
       "      <td>7760000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.9421</td>\n",
       "      <td>103225286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGD</td>\n",
       "      <td>Safe and Green Development Corp</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Real Estate - Development</td>\n",
       "      <td>USA</td>\n",
       "      <td>9900000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>58268257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SLNH</td>\n",
       "      <td>Soluna Holdings Inc</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Capital Markets</td>\n",
       "      <td>USA</td>\n",
       "      <td>10240000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.1091</td>\n",
       "      <td>13427345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SYTA</td>\n",
       "      <td>Siyata Mobile Inc</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Communication Equipment</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1430000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>556257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WYY</td>\n",
       "      <td>Widepoint Corp</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Information Technology Services</td>\n",
       "      <td>USA</td>\n",
       "      <td>23690000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>1118643.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker                          Company              Sector  \\\n",
       "0   DTCK           Davis Commodities Ltd.  Consumer Defensive   \n",
       "1   MULN            Mullen Automotive Inc   Consumer Cyclical   \n",
       "2   OXBR         Oxbridge Re Holdings Ltd           Financial   \n",
       "3   REBN                Reborn Coffee Inc   Consumer Cyclical   \n",
       "4    SGD  Safe and Green Development Corp         Real Estate   \n",
       "5   SLNH              Soluna Holdings Inc           Financial   \n",
       "6   SYTA                Siyata Mobile Inc          Technology   \n",
       "7    WYY                   Widepoint Corp          Technology   \n",
       "\n",
       "                          Industry         Country  Market Cap   P/E  Price  \\\n",
       "0                    Farm Products       Singapore  33320000.0  8.27   1.36   \n",
       "1               Auto Manufacturers             USA  46110000.0   NaN   7.04   \n",
       "2          Insurance - Reinsurance  Cayman Islands   9920000.0   NaN   1.65   \n",
       "3                      Restaurants             USA   7760000.0   NaN   3.36   \n",
       "4        Real Estate - Development             USA   9900000.0   NaN   0.69   \n",
       "5                  Capital Markets             USA  10240000.0   NaN   2.69   \n",
       "6          Communication Equipment          Canada   1430000.0   NaN   2.34   \n",
       "7  Information Technology Services             USA  23690000.0   NaN   2.48   \n",
       "\n",
       "   Change       Volume  \n",
       "0  0.1148    3356710.0  \n",
       "1  0.2265   18384953.0  \n",
       "2  0.2992     224130.0  \n",
       "3  0.9421  103225286.0  \n",
       "4  0.7674   58268257.0  \n",
       "5  0.1091   13427345.0  \n",
       "6  0.1056     556257.0  \n",
       "7  0.1114    1118643.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to get the filtered stocks:\n",
    "def get_filtered_stocks():\n",
    "    \"\"\"\n",
    "    Returns a list of tickers with:\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    foverview = Overview()\n",
    "    foverview.set_filter(filters_dict=FILTERS_DICT)\n",
    "    df_overview = foverview.screener_view()\n",
    "    if not os.path.exists('out'): #ensures you have an 'out' folder ready\n",
    "        os.makedirs('out')\n",
    "    df_overview.to_csv('out/Overview.csv', index=False)\n",
    "    \n",
    "    tickers = df_overview['Ticker'].to_list()\n",
    "    display(df_overview)\n",
    "    return tickers\n",
    "\n",
    "\n",
    "\n",
    "undervalued = get_filtered_stocks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTCK done, 7 stock tickers left\n",
      "MULN done, 6 stock tickers left\n",
      "OXBR done, 5 stock tickers left\n",
      "REBN done, 4 stock tickers left\n",
      "SGD done, 3 stock tickers left\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mc:\\Users\\Oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 111\u001b[0m\n\u001b[0;32m    109\u001b[0m sentiments \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m undervalued:\n\u001b[1;32m--> 111\u001b[0m     sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mget_ticker_news_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sentiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m         sentiments\u001b[38;5;241m.\u001b[39mappend(sentiment)\n",
      "Cell \u001b[1;32mIn[19], line 23\u001b[0m, in \u001b[0;36mget_ticker_news_sentiment\u001b[1;34m(ticker)\u001b[0m\n\u001b[0;32m     20\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProsusAI/finbert\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m ticker_news \u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mTicker(ticker)\n\u001b[1;32m---> 23\u001b[0m news_list \u001b[38;5;241m=\u001b[39m \u001b[43mticker_news\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_news\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m news_list: \u001b[38;5;66;03m# If there is no news for the ticker\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\yfinance\\base.py:512\u001b[0m, in \u001b[0;36mTickerBase.get_news\u001b[1;34m(self, proxy)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWill be right back\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mtext:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** YAHOO! FINANCE IS CURRENTLY DOWN! ***\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur engineers are working quickly to resolve \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe issue. Thank you for your patience.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 512\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# parse news\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_news \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[1;32mc:\\Users\\Oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Function to get the sentiment of the news articles for a given ticker.\n",
    "# This may run for a good few minutes, depending on the number of filtered tickers / articles. (seen approx 2-7 minutes total)\n",
    "\n",
    "\n",
    "ALLOW_TOKENIZATION = False # True: the model will feed the article into the model in chunks of 512 tokens, \n",
    "#                            False: the model will consider only the first sentences of the article until the total number of tokens does not exceed 512\n",
    "\n",
    "def get_ticker_news_sentiment(ticker):\n",
    "    \"\"\"\n",
    "    Returns a Pandas dataframe of the given ticker's most recent news article headlines,\n",
    "    with the overal sentiment of each article.\n",
    "\n",
    "    Args:\n",
    "        ticker (string)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: {'Date', 'Article title', Article sentiment'}\n",
    "    \"\"\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "    ticker_news = yf.Ticker(ticker)\n",
    "    try:\n",
    "        news_list = ticker_news.get_news()\n",
    "    except:\n",
    "        print(f\"Error getting news for ticker {ticker}\")\n",
    "        return\n",
    "    \n",
    "    extractor = Goose()\n",
    "    pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "    data = []\n",
    "    \n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "                \n",
    "    for dic in news_list:\n",
    "        title = dic['title']\n",
    "        response = get(dic['link'], headers=headers)\n",
    "        \n",
    "        article = extractor.extract(raw_html=response.content)\n",
    "        text = article.cleaned_text\n",
    "        date = article.publish_date\n",
    "        \n",
    "        if date == None: # If the date is not found in the article, try to find it in the article's html\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Yahoo Finance usually stores the publication date in a 'time' tag with the class 'caas-attr-meta-time'\n",
    "            date_tag = soup.find('time', {'class': 'caas-attr-meta-time'})\n",
    "            if date_tag:\n",
    "                date = date_tag['datetime']\n",
    "            else:\n",
    "                print('Publication date not found, article link for debugging', dic['link'])\n",
    "            \n",
    "            \n",
    "        if len(text) > 512:\n",
    "            if ALLOW_TOKENIZATION: # feed the article into the model in chunks of 512 tokens\n",
    "                inputs = tokenizer.encode_plus(\n",
    "                    text,\n",
    "                    max_length=510,\n",
    "                    truncation='longest_first',  # Truncate the longest sequences first\n",
    "                    padding='max_length',  # Pad sequences to the max length\n",
    "                    return_tensors='pt',  # Return PyTorch tensors\n",
    "                )\n",
    "                \n",
    "                # Convert tensor to list and then to string\n",
    "                input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "                new_text = tokenizer.decode(input_ids)\n",
    "            \n",
    "            else: # count the sentences until the total number of tokens does not exceed 512 (consider only first sentences of the article)\n",
    "                # Split the text into sentences\n",
    "                sentences = sent_tokenize(text)\n",
    "\n",
    "                # Initialize an empty string for the new text\n",
    "                new_text = ''\n",
    "\n",
    "                # Add sentences to the new text until it exceeds 512 tokens\n",
    "                for sentence in sentences:\n",
    "                    if len(new_text.split()) + len(sentence) > 512:\n",
    "                        new_text += ' ' + sentence\n",
    "                    break\n",
    "\n",
    "            # Now you can pass 'inputs' to your model\n",
    "            results = pipe(new_text)\n",
    "\n",
    "            data.append({'Ticker':f'{ticker}',\n",
    "                         'Date':f'{date}',\n",
    "                         'Article title':f'{title}',\n",
    "                         'Article sentiment':results[0]['label']})\n",
    "\n",
    "        else:\n",
    "            results = pipe(text)\n",
    "            data.append({'Ticker':f'{ticker}',\n",
    "                         'Date':f'{date}',\n",
    "                         'Article title':f'{title}',\n",
    "                         'Article sentiment':results[0]['label']})\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def generate_csv(sentiment,ticker):\n",
    "    sentiment.to_csv(f'out/{ticker}.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "#undervalued = get_filtered_stocks()\n",
    "\n",
    "sentiments = []\n",
    "for ticker in undervalued:\n",
    "    sentiment = get_ticker_news_sentiment(ticker)\n",
    "    if sentiment is not None:\n",
    "        sentiments.append(sentiment)\n",
    "        generate_csv(sentiment,ticker)\n",
    "    else:\n",
    "        print(f'No news found for {ticker}')\n",
    "    print(f'{ticker} done, {len(undervalued) - undervalued.index(ticker) - 1} stock tickers left')\t\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mc:\\Users\\Oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ticker \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSLNH\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mget_ticker_news_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 23\u001b[0m, in \u001b[0;36mget_ticker_news_sentiment\u001b[1;34m(ticker)\u001b[0m\n\u001b[0;32m     20\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProsusAI/finbert\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m ticker_news \u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mTicker(ticker)\n\u001b[1;32m---> 23\u001b[0m news_list \u001b[38;5;241m=\u001b[39m \u001b[43mticker_news\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_news\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m news_list: \u001b[38;5;66;03m# If there is no news for the ticker\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\yfinance\\base.py:512\u001b[0m, in \u001b[0;36mTickerBase.get_news\u001b[1;34m(self, proxy)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWill be right back\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mtext:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** YAHOO! FINANCE IS CURRENTLY DOWN! ***\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur engineers are working quickly to resolve \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe issue. Thank you for your patience.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 512\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# parse news\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_news \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[1;32mc:\\Users\\Oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "ticker = 'SLNH'\n",
    "sentiment = get_ticker_news_sentiment(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the news:\n",
    "for i in range(len(sentiments)):\n",
    "    display(sentiments[i])  # This will print the first element of each inner list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random junk code:\n",
    "quote = finvizfinance('SGE')\n",
    "\n",
    "df = quote.ticker_inside_trader()\n",
    "from datetime import datetime\n",
    "# Get today's date\n",
    "today = datetime.today().date()\n",
    "\n",
    "# Get the news and filter it to get only today's news\n",
    "df = quote.ticker_news()\n",
    "df = df[df['Date'].dt.date == today]\n",
    "df\n",
    "\n",
    "\n",
    "df = quote.ticker_fundament()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
