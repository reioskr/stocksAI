{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment the following lines by removing ''' if you haven't installed the dependencies yet)\n",
    "'''\n",
    "%pip install finvizfinance\n",
    "%pip install pandas\n",
    "%pip install transformers\n",
    "%pip install yfinance\n",
    "%pip install goose3\n",
    "%pip install requests\n",
    "%pip install ipywidgets\n",
    "\n",
    "%pip install torch\n",
    "%pip install tensorflow\n",
    "%pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from finvizfinance.screener.overview import Overview # type: ignore\n",
    "from finvizfinance.quote import finvizfinance        # type: ignore\n",
    "from IPython.display import display                  # type: ignore\n",
    "\n",
    "import pandas as pd                 # type: ignore\n",
    "from transformers import pipeline   # type: ignore\n",
    "import yfinance as yf               # type: ignore\n",
    "from goose3 import Goose            # type: ignore\n",
    "from requests import get            # type: ignore\n",
    "\n",
    "from nltk.tokenize import sent_tokenize # type: ignore\n",
    "from transformers import AutoTokenizer  # type: ignore\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Other general settings\n",
    "pd.set_option('display.max_colwidth', None) # Display full text in pandas dataframe / no line wrapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filters dictionary, i.e filter the stocks based on the following criteria:\n",
    "FILTERS_DICT = {\n",
    "    'Performance': 'Today +10%',     # Day increase 10%\n",
    "    'Relative Volume': 'Over 5',       # High Relative Volume\n",
    "    'Price': 'Under $20',              # Price under 20 USD\n",
    "    'Float': 'Under 10M'               # Float under 10 million\n",
    "}\n",
    "\n",
    "# Alternative filtering to consider:\n",
    "'''\n",
    "FILTERS_DICT = {'Debt/Equity':'Under 1',                 # Positive Operating Margin\n",
    "                'PEG':'Low (<1)',                        # Debt-to-Equity ratio under 1\n",
    "                'Operating Margin':'Positive (>0%)',     # Low P/B (under 1)\n",
    "                'P/B':'Low (<1)',                        # Low P/E ratio (under 15)\n",
    "                'P/E':'Low (<15)',                       # Low PEG ratio (under 1)\n",
    "                'InsiderTransactions':'Positive (>0%)<'} # Positive Insider Transactions\n",
    "'''\n",
    "\n",
    "\n",
    "# The filters and general manual link for the finvizfinance library: https://finvizfinance.readthedocs.io/_/downloads/en/latest/pdf/ \n",
    "# Possible filters can be found by running the following code:\n",
    "\n",
    "#from finvizfinance.screener.overview import Overview # type: ignore\n",
    "#foverview = Overview()    # Create Overview object\n",
    "#foverview.get_filters()   # Get list of all possible filters\n",
    "\n",
    "# And after to see the possible options for a filter, run the following code:\n",
    "#foverview.get_filter_options('Relative Volume') # Get list of all possible options for a filter, example on 'Relative Volume'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the filtered stocks:\n",
    "def get_filtered_stocks():\n",
    "    \"\"\"\n",
    "    Returns a list of tickers with:\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    foverview = Overview()\n",
    "    foverview.set_filter(filters_dict=FILTERS_DICT)\n",
    "    df_overview = foverview.screener_view()\n",
    "    if not os.path.exists('out'): #ensures you have an 'out' folder ready\n",
    "        os.makedirs('out')\n",
    "    df_overview.to_csv('out/Overview.csv', index=False)\n",
    "    \n",
    "    tickers = df_overview['Ticker'].to_list()\n",
    "    display(df_overview)\n",
    "    return tickers\n",
    "\n",
    "\n",
    "\n",
    "undervalued = get_filtered_stocks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the sentiment of the news articles for a given ticker.\n",
    "# This may run for a good few minutes, depending on the number of filtered tickers / articles. (seen approx 2-7 minutes total)\n",
    "\n",
    "\n",
    "ALLOW_TOKENIZATION = False # True: the model will feed the article into the model in chunks of 512 tokens, \n",
    "#                            False: the model will consider only the first sentences of the article until the total number of tokens does not exceed 512\n",
    "\n",
    "def get_ticker_news_sentiment(ticker):\n",
    "    \"\"\"\n",
    "    Returns a Pandas dataframe of the given ticker's most recent news article headlines,\n",
    "    with the overal sentiment of each article.\n",
    "\n",
    "    Args:\n",
    "        ticker (string)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: {'Date', 'Article title', Article sentiment'}\n",
    "    \"\"\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "    ticker_news = yf.Ticker(ticker)\n",
    "    news_list = ticker_news.get_news()\n",
    "    extractor = Goose()\n",
    "    pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "    data = []\n",
    "    \n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "                \n",
    "    for dic in news_list:\n",
    "        title = dic['title']\n",
    "        response = get(dic['link'], headers=headers)\n",
    "        article = extractor.extract(raw_html=response.content)\n",
    "        text = article.cleaned_text\n",
    "        date = article.publish_date\n",
    "        \n",
    "        if date == None: # If the date is not found in the article, try to find it in the article's html\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Yahoo Finance usually stores the publication date in a 'time' tag with the class 'caas-attr-meta-time'\n",
    "            date_tag = soup.find('time', {'class': 'caas-attr-meta-time'})\n",
    "            if date_tag:\n",
    "                date = date_tag['datetime']\n",
    "            else:\n",
    "                print('Publication date not found, article link for debugging', dic['link'])\n",
    "            \n",
    "            \n",
    "        if len(text) > 512:\n",
    "            if ALLOW_TOKENIZATION: # feed the article into the model in chunks of 512 tokens\n",
    "                inputs = tokenizer.encode_plus(\n",
    "                    text,\n",
    "                    max_length=510,\n",
    "                    truncation='longest_first',  # Truncate the longest sequences first\n",
    "                    padding='max_length',  # Pad sequences to the max length\n",
    "                    return_tensors='pt',  # Return PyTorch tensors\n",
    "                )\n",
    "                \n",
    "                # Convert tensor to list and then to string\n",
    "                input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "                new_text = tokenizer.decode(input_ids)\n",
    "            \n",
    "            else: # count the sentences until the total number of tokens does not exceed 512 (consider only first sentences of the article)\n",
    "                # Split the text into sentences\n",
    "                sentences = sent_tokenize(text)\n",
    "\n",
    "                # Initialize an empty string for the new text\n",
    "                new_text = ''\n",
    "\n",
    "                # Add sentences to the new text until it exceeds 512 tokens\n",
    "                for sentence in sentences:\n",
    "                    if len(new_text.split()) + len(sentence) > 512:\n",
    "                        new_text += ' ' + sentence\n",
    "                    break\n",
    "\n",
    "            # Now you can pass 'inputs' to your model\n",
    "            results = pipe(new_text)\n",
    "\n",
    "            data.append({'Ticker':f'{ticker}',\n",
    "                         'Date':f'{date}',\n",
    "                         'Article title':f'{title}',\n",
    "                         'Article sentiment':results[0]['label']})\n",
    "\n",
    "        else:\n",
    "            results = pipe(text)\n",
    "            data.append({'Ticker':f'{ticker}',\n",
    "                         'Date':f'{date}',\n",
    "                         'Article title':f'{title}',\n",
    "                         'Article sentiment':results[0]['label']})\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def generate_csv(ticker):\n",
    "    get_ticker_news_sentiment(ticker).to_csv(f'out/{ticker}.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "#undervalued = get_filtered_stocks()\n",
    "\n",
    "sentiments = []\n",
    "for ticker in undervalued:\n",
    "    generate_csv(ticker)\n",
    "    sentiments.append(get_ticker_news_sentiment(ticker))\n",
    "    print(f'{ticker} done, {len(undervalued) - undervalued.index(ticker) - 1} stock tickers left')\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the news:\n",
    "for i in range(len(sentiments)):\n",
    "    display(sentiments[i])  # This will print the first element of each inner list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random junk code:\n",
    "quote = finvizfinance('SGE')\n",
    "\n",
    "df = quote.ticker_inside_trader()\n",
    "from datetime import datetime\n",
    "# Get today's date\n",
    "today = datetime.today().date()\n",
    "\n",
    "# Get the news and filter it to get only today's news\n",
    "df = quote.ticker_news()\n",
    "df = df[df['Date'].dt.date == today]\n",
    "df\n",
    "\n",
    "\n",
    "df = quote.ticker_fundament()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
